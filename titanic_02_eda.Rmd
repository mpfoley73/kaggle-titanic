---
title: "Kaggle - Titanic"
subtitle: "Step 2: Exploratory Analysis"
author: "Michael Foley"
date: "5/7/2020"
output: 
  html_document:
    theme: flatly
    toc: true
    highlight: haddock
    fig_width: 9
    fig_caption: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


This is a survey of the Titanic data.  The univariate analysis characterizes the predictor distributions.  The bivariate analysis characterizes relationships among the predictors and with the response variable.  The influential outliers analysis searches for problematic observations.  

Conclusions:

* Factor variables `Title` and `Employee` have near-zero-variance.
* Nearly all of the quantitative predictors suffer from skew.
* `Sex` moderates `Pclass` and `Embarked`.
* Created grouping variable `AgeCohort`. It should interact with `Age` and `Sex`.
* Created grouping variable `TicketNCohort`.  It should interact with `TicketN`.
* Created net survivors predictor `NetSurv` with values truncated at -1 and +1.


# Setup

```{r message=FALSE}
library(tidyverse)
library(caret)  # for nearZeroVar()
library(e1071)  # for skewness()
library(broom)  # for tidy()
library(GGally) # for ggpairs()
library(gridExtra) 
library(janitor)
```


# Load Data

The initial data management created the data set `full`, with training rows indexed by `train_index`.

```{r warning=FALSE, message=FALSE}
load("./titanic_01.RData")

glimpse(full)
```

# Univariate Analysis

In this section I will look at data distributions. For factor variables, I am interested in which have near-zero-variance. For quantitative variables, I am looking for significant skew. 

Conclusions from this section are:

* Factor variables `Title` and `Employee` have near-zero-variance.
* Nearly all of the quantitative predictors suffer from skew.


It will be handy to classify the predictors by data type.

```{r}
preds <- full %>% 
  select(-Survived, -PassengerId, -Surname, -Name, -Ticket, -Cabin, -Fare) %>% 
  colnames()
preds_class <- full[, preds] %>% map(class) %>% unlist()
preds_factor <- subset(preds_class, preds_class == "factor") %>% names()
preds_numeric <- subset(preds_class, preds_class %in% c("numeric", "integer")) %>% names()
mdl_vars <- c("Survived", preds)
rm(preds_class)

assertthat::are_equal(length(c(preds_factor, preds_numeric)), length(preds))
```

## Factor Variables

Inspect each factor variable, looking for near-zero-variance (NZV). I might collapse them to prevent zero-variance in CV folds. `caret::nearZeroVar()` defines NZV as a frequency ratio of the most common value to the second most common value frequency >= 19/5 and a unique value percentage <= 10%. (*DataCamp course Machine Learning Toolbox suggests more aggressive thresholds of frequency ratio >= 2 and unique value percentage <= 20%*).

```{r warning=FALSE}
dummies <- dummyVars(~., data = full[, preds_factor], fullRank = FALSE)
dummy_dat <- as.data.frame(predict(dummies, full[, preds_factor]))
(nzv <- dummy_dat %>%
    nearZeroVar(saveMetrics= TRUE)
)
```

The problematic predictors are `Title` and `Employee`. 

Here is a visualization of the data. Ideally, you want the vars to land in the top left quadrant.  NZV are in the lower right quadrant.

```{r}
nzv %>%
  data.frame() %>% rownames_to_column(var = "col") %>%
  separate(col, sep = "\\.", into = c("col", "level"), ) %>%
  filter(!is.na(level)) %>%
  ggplot(aes(x = freqRatio, y = percentUnique, 
             color = fct_rev(factor(nzv, labels = c("(okay)", "NZV"))), 
             label = level)) +
  geom_text(check_overlap = TRUE, size = 2, na.rm = TRUE) +
  geom_point(size = 3, alpha = 0.6, na.rm = TRUE) +
  geom_hline(yintercept = 10, linetype = "dashed") +
  geom_vline(xintercept = 95/5, linetype = "dashed") +
  theme(legend.position = "top") +
  labs(title = "Near-Zero Variance of Factor Variables", color = "") +
  facet_wrap(~col)

rm(dummies, dummy_dat, nzv)
```


## Quantitative Variables

Skew can contribute to violation of linearity in linear regressions. Iâ€™ll check which variables have significant skew. Skew between 0.5 and 1.0 is generally considered moderate, and skew greater than 1 severe. In the following charts, negligibly skewed predictors are colored teal (there are none), moderately skewed predictors are colored gold and the severely skewed predictors are colored red.

```{r message=FALSE}
col_skew <- map(full[, preds_numeric], skewness) %>% unlist()
col_skew_is_mod <- names(col_skew[abs(col_skew) > .5 & abs(col_skew) <= 1.0])
col_skew_is_high <- names(col_skew[abs(col_skew) > 1.0])
p <- map(
  colnames(full[, preds_numeric]),
  ~ ggplot(full, aes_string(x = .x)) +
    geom_histogram(fill = case_when(.x %in% col_skew_is_mod ~ "goldenrod", 
                                    .x %in% col_skew_is_high ~ "orangered4",
                                    TRUE ~ "cadetblue")) +
    labs(y = "", x = "", title = .x) +
    theme(axis.text.y=element_blank(), plot.title = element_text(size = 10))
)
exec(grid.arrange, ncol = 2, !!!p)

rm(col_skew, col_skew_is_high, col_skew_is_mod)
```

Nearly all of the quantitative predictors suffer from skew.  It may make sense to transform these variables in modeling.

# Bivariate Analysis

In this section I will look at inter-variable relationships. For factor variables, I am interested in which levels have significantly different log survival odds. For quantitative variables, I am looking for linear relationships with log survival odds and low correlations with each other.  I am also interested in any variable interactions that might improve the linearity assumptions of linear models.

Conclusions:

* `Sex` moderates `Pclass` and `Embarked`.
* Created grouping variable `AgeCohort`. It should interact with `Age` and `Sex`.
* Created grouping variable `TicketNCohort`.  It should interact with `TicketN`.
* Created net survivors predictor `NetSurv` with values truncated at -1 and +1.


Before I begin, let's get some initial perspective which variables are correlated with survival.

```{r cache=TRUE, warning=FALSE}
dummies_fullrank <- dummyVars(~., data = full[, mdl_vars], fullRank = TRUE)
full_dum <- as.data.frame(predict(dummies_fullrank, full[, mdl_vars]))

cor_out <- full_dum[train_index, ] %>% cor()
cor_out[, "Survived.Yes"] %>% abs() %>% sort(decreasing = TRUE) %>% head(11)
```
 
`Title` and `Sex` are by the far the best predictors of survival (`Title` basically combines sex and age). `Pclass` and `FarePerPass` are next.  Embarkation port is also important. So far it seems your best bet for survival is to be a rich woman.

For this analysis I'll define a plotting function with a logistic regression fit, and an odds ratio table function.

```{r}
model_bin <- function(dat, fmla) {
  mdl <- train(
    as.formula(fmla),
    dat,
    method = "glm", family = "binomial",
    metric = "Accuracy",
    trControl = trainControl(method = "cv", n = 10)      
  )
}

plot_bin <- function(dat, x_var, facet_var, fmla) {
  dat %>% 
    group_by(!!sym(x_var), !!sym(facet_var), Survived, pred) %>%
    summarize(n = n()) %>%
    pivot_wider(names_from = "Survived", values_from = n, names_prefix = "Survived.") %>%
    replace_na(list(Survived.No = 0, Survived.Yes = 0)) %>%
    mutate(
      N = Survived.No + Survived.Yes,
      prop = Survived.Yes / N,
      odds = prop / (1 - prop),
      log_odds = log(odds),
      log_odds = case_when(log_odds == -Inf ~ -3, 
                           log_odds ==  Inf ~  3, 
                           TRUE ~ log_odds),
      pred_log_odds = log(pred / (1 - pred))
    ) %>%
    ggplot(aes(x = !!sym(x_var))) +
      geom_point(aes(y = log_odds, size = N, color = "Actual"), alpha = 0.6) +
      geom_point(aes(y = pred_log_odds, color = "Predicted")) +
      scale_color_manual(values = c("cadetblue", "goldenrod")) +
      theme(axis.text.x = element_text(angle = 90)) +
      labs(title = fmla, x = x_var, color = "") +
      facet_wrap(facets = facet_var)
}

write_tab <- function(dat, group_var){
  fmla <- paste0("Survived ~ ", group_var)

  mdl_obj <- glm(as.formula(fmla), data = dat, family = "binomial") %>%
    tidy() %>%
    mutate(term = str_remove(term, group_var), OR = exp(estimate)) %>% 
    filter(term != "(Intercept)") %>%
    select(term, OR)

  dat %>%
  group_by(!!sym(group_var)) %>%
  summarise(
    Lived = sum(if_else(Survived == "Yes", 1, 0)),
    Died = sum(if_else(Survived == "No", 1, 0)),
    N = Lived + Died,
    Surv = Lived / N,
    Odds = Surv / (1 - Surv) 
  ) %>%
  ungroup() %>%
  rename(term = !!sym(group_var)) %>%
  mutate(term = as.character(term), Surv = Surv * 100) %>%
  left_join(mdl_obj, by = "term") %>%
  select(term, N, Surv, Odds, OR) %>%
  flextable::flextable() %>% 
  flextable::colformat_int(j = 2) %>% 
  flextable::colformat_num(j = 3, digits = 0, suffix = "%") %>%
  flextable::colformat_num(j = c(4:5)) %>%
  flextable::set_caption(fmla)
}
```
## Sex

In the training data set, 19% of males survived and 74% of the females survived.  We should get 74-81% accuracy just by predicting all males perish and all females survive.

```{r}
write_tab(full[train_index, ], group_var = "Sex")
```


## Age

Here is the survival log-odds for `Age`.  Children of both sexes had relatively good survival odds.  For males, the children reverse a generally positive relationship with age.  The female relationship seems okay.

```{r}
fmla <- "Survived ~ Sex*Age"
dat <- full[train_index, ] %>% mutate(age_bin = cut(Age, 16))
mdl <- dat %>% model_bin(fmla)
dat$pred <- mdl$finalModel$fitted.values  
plot_bin(dat, x_var = "age_bin", facet_var = "Sex", fmla = fmla)
```

So maybe there should be an `AgeCohort = c(lte10, gt10)` factor variable that moderates `Age`.

```{r}
fmla <- "Survived ~ Sex*Age*AgeCohort"
dat <- full[train_index, ] %>% 
  mutate(
    AgeCohort = factor(if_else(Age <= 10, "lte10", "gt10")),
    AgeBin = cut(Age, 16)
  )
mdl <- dat %>% model_bin(fmla)
dat$pred <- mdl$finalModel$fitted.values  
plot_bin(dat, x_var = "AgeBin", facet_var = "Sex", fmla = fmla)
tidy(mdl$finalModel) %>% flextable::regulartable() %>% 
  flextable::colformat_num(j = 2:5, digits = 3) %>%
  flextable::autofit()
```
Better.  I'll create the `AgeCohort` predictor and plan to interact it with `Age` and `Sex` since the slopes differ.

```{r}
full <- full %>%
  mutate(AgeCohort = factor(if_else(Age <= 10, "lte10", "gt10"), 
                            levels = c("lte10", "gt10")))
```

## Title

Title is closely related to `Sex` and `Age`.  Is it still useful?  

Here is the sex/age breakdown. 53-54% of children survive (same for males and females). Over age 10, 17% of males survive and 77% of females survive.

```{r}
write_tab(full[train_index, ] %>% filter(Sex == "male"), group_var = "AgeCohort")
write_tab(full[train_index, ] %>% filter(Sex == "female"), group_var = "AgeCohort")
```


```{r}
full[train_index, ] %>% 
  tabyl(AgeCohort, Survived, Sex) %>%
  adorn_totals(where = c("row", "col")) %>%
  adorn_percentages() %>% adorn_pct_formatting() %>% adorn_ns() %>%
#  adorn_title("combined") %>%
#  untabyl() %>% 
  data.frame() %>%
  flextable::regulartable() %>% 
  flextable::autofit()
```

Combining `AgeCohort` and `Title`, 34/40 "Master" are under age 10, and 515/517 "Mr" are over age 10.  "Miss" has less separation: 147/182 "Miss" are over age 10. I suspect "Miss" means *any* female who has not yet married.

```{r}
full[train_index, ] %>% 
  tabyl(Title, Survived, AgeCohort) %>%
  adorn_totals(where = c("row", "col")) %>%
  adorn_percentages() %>% adorn_pct_formatting() %>% adorn_ns() %>%
  adorn_title("combined") %>%
  data.frame() %>%
  flextable::regulartable() %>% 
  flextable::autofit()
#  knitr::kable()
```

So, do passengers with a title other than Master/Miss/Mrs/Mr have a better chance of surviving?  A little: 44% of titled persons survived compared to 38% of untitled.  But only 27/891 = 3% of passengers have a title.

```{r}
full[train_index, ] %>% 
  mutate(HasTitle = if_else(Title %in% c("Mr", "Mrs", "Master", "Miss"), "No", "Yes")) %>%
  tabyl(HasTitle, Survived) %>%
  adorn_totals(where = c("row", "col")) %>%
  adorn_percentages() %>% adorn_pct_formatting() %>% adorn_ns() %>%
  adorn_title("combined") %>%
  data.frame() %>%
  flextable::regulartable() %>% 
  flextable::autofit()
```

I think the conclusion here is that `Title` is redundant to `AgeCohort` and `Sex` and I should not include it in the models.

## Pclass

Third class passengers (`Pclass = 3`) had a rough go of it.  Male survival odds are cut in half when dropping to 2nd class, then stay about the same for 3rd class.  Female survival odds stayed the same for 2nd class, but halved when dropping to 3rd class.  N-size is small for the females though.  Looks like all three classes are important, but should be moderated by `Sex`.

```{r}
fmla <- "Survived ~ Pclass*Sex"
dat <- full[train_index, ]
mdl <- dat %>% model_bin(fmla)
dat$pred <- mdl$finalModel$fitted.values  
plot_bin(dat, x_var = "Pclass", facet_var = "Sex", fmla = fmla)
```

## TicketN

Traveling with with others helps - but only to a point!  Both male and female survival odds increase with ticket size to n = 4, then they fall.

```{r}
fmla <- "Survived ~ TicketN + Sex"
dat <- full[train_index, ]
mdl <- dat %>% model_bin(fmla)
dat$pred <- mdl$finalModel$fitted.values  
plot_bin(dat, x_var = "TicketN", facet_var = "Sex", fmla = fmla)
```

How about a dummy variable `TicketNCohort = c("lte4", "gt4")`.

```{r}
fmla <- "Survived ~ TicketN*TicketNCohort + Sex"
dat <- full[train_index, ] %>%
  mutate(TicketNCohort = factor(if_else(TicketN <= 4, "lte4", "gt4")))
mdl <- dat %>% model_bin(fmla)
dat$pred <- mdl$finalModel$fitted.values  
plot_bin(dat, x_var = "TicketN", facet_var = "Sex", fmla = fmla)
```

Better.  I'll create the `TicketNCohort` predictor and plan to interact it with `TicketN`.

```{r}
full <- full %>%
  mutate(TicketNCohort = factor(if_else(TicketN <= 4, "lte4", "gt4"), 
                            levels = c("lte4", "gt4")))
```


## SibSp

Survival odds fall with increasing numbers of spouse+siblings.  Maybe people made sure at least on child in a family got aboard a raft.  Males traveling with no spouse or sibling is a conspicuously frequent and dubious group. 

```{r}
fmla <- "Survived ~ SibSp + Sex"
dat <- full[train_index, ]
mdl <- full[train_index, ] %>% model_bin(fmla)
dat$pred <- mdl$finalModel$fitted.values  
plot_bin(dat, x_var = "SibSp", facet_var = "Sex", fmla = fmla)
```

Including the newly-created `TicketNCohort` variable seems to help.

```{r}
fmla <- "Survived ~ SibSp + Sex + TicketN*TicketNCohort"
dat <- full[train_index, ]
mdl <- full[train_index, ] %>% model_bin(fmla)
dat$pred <- mdl$finalModel$fitted.values  
plot_bin(dat, x_var = "SibSp", facet_var = "Sex", fmla = fmla)
```

No actions need to be taken with this variable - just include it in the model as-is.

## Parch

Survival odds fall with increasing numbers of parents and children.  Again, males traveling alone are in trouble. 

```{r}
fmla <- "Survived ~ Parch + Sex"
dat <- full[train_index, ]
mdl <- full[train_index, ] %>% model_bin(fmla)
dat$pred <- mdl$finalModel$fitted.values  
plot_bin(dat, x_var = "Parch", facet_var = "Sex", fmla = fmla)
```

Including the newly-created `TicketNCohort` variable seems to help.  Hard to tell, actually.

```{r}
fmla <- "Survived ~ Parch + Sex + TicketN*TicketNCohort"
dat <- full[train_index, ]
mdl <- full[train_index, ] %>% model_bin(fmla)
dat$pred <- mdl$finalModel$fitted.values  
plot_bin(dat, x_var = "Parch", facet_var = "Sex", fmla = fmla)
```

No actions need to be taken with this variable - just include it in the model as-is.

## Embarked

Embarking from Queenstown was a death sentence for males for some reason.  `Embarked` should interact with `Sex`.

```{r}
fmla <- "Survived ~ Embarked*Sex"
dat <- full[train_index, ]
mdl <- dat %>% model_bin(fmla)
dat$pred <- mdl$finalModel$fitted.values  
plot_bin(dat, x_var = "Embarked", facet_var = "Sex", fmla = fmla)
```

## FarePerPass

Here is the survival log-odds for `FarePerPass`.  I don't really see much of a relationship.  I think the thing to do is to leave the variable alone, include it in the model and see what happens.

```{r}
fmla <- "Survived ~ Sex + FarePerPass"
dat <- full[train_index, ] %>% mutate(FarePerPassBin = cut(FarePerPass, 10))
mdl <- dat %>% model_bin(fmla)
dat$pred <- mdl$finalModel$fitted.values  
plot_bin(dat, x_var = "FarePerPassBin", facet_var = "Sex", fmla = fmla)
```


## Employee

93% of employees perished, but n = 14. Maybe this variable is useful in a tree model, I don't know. I'll leave it in, but I don't expect much.

```{r}
tabyl(full[train_index, ], Employee, Survived) %>%
  adorn_totals(where = c("row", "col")) %>%
  adorn_percentages() %>% adorn_pct_formatting() %>% adorn_ns() %>%
  adorn_title("combined") %>%
  data.frame() %>%
  flextable::regulartable() %>% 
  flextable::autofit()
```

## Deck

Generally, it's better to have a cabin on a deck at the top of the alphabet.  No interaction with `Sex`.  Not a lot of separation among the decks.  Deck A has a low n-size.  I'll leave this variable alone.

```{r}
fmla <- "Survived ~ Deck + Sex"
dat <- full[train_index, ]
mdl <- dat %>% model_bin(fmla)
dat$pred <- mdl$finalModel$fitted.values  
plot_bin(dat, x_var = "Deck", facet_var = "Sex", fmla = fmla)
```


## NetSurv

Is the survival status of the other passengers on the ticket predictive of your survival odds?  Create feature `NetSurv` to check.

```{r}
full <- full %>%
  group_by(Ticket) %>%
  mutate(
    SurvN = sum(Survived == "Yes", na.rm = TRUE),
    PrshN = sum(Survived == "No", na.rm = TRUE)
  ) %>% 
  ungroup() %>%
  mutate(
    SurvN = SurvN - if_else(!is.na(Survived) & Survived == "Yes", 1, 0),
    PrshN = PrshN - if_else(!is.na(Survived) & Survived == "No", 1, 0),
    NetSurv = SurvN - PrshN,
  ) %>%
  select(-SurvN, -PrshN)
```

`NetSurv` certainly does appear to be predictive.  The tails are thinly populated and the linearity breaks down. 

```{r}
fmla <- "Survived ~ NetSurv + Sex"
dat <- full[train_index, ]
mdl <- dat %>% model_bin(fmla)
dat$pred <- mdl$finalModel$fitted.values  
plot_bin(dat, x_var = "NetSurv", facet_var = "Sex", fmla = fmla)
```

 I can probably collapse the tails.

```{r}
full[train_index, ] %>% group_by(NetSurv) %>% summarize(n = n(), mean = mean(Survived == "Yes"))
```

```{r}
full$NetSurv <- case_when(full$NetSurv <= -1 ~ -1,
                          full$NetSurv >=  1 ~  1,
                          TRUE ~ 0)
```

This could be an ordinal factor variable, but I think it works fine as a numeric.

```{r}
fmla <- "Survived ~ NetSurv + Sex"
dat <- full[train_index, ]
mdl <- dat %>% model_bin(fmla)
dat$pred <- mdl$finalModel$fitted.values  
plot_bin(dat, x_var = "NetSurv", facet_var = "Sex", fmla = fmla)
```

## Collinearity

There predictor set has grown from 11 variables to 13.  I'm adding factor variables `AgeCohort` and `TicketNCohort`, and numeric variable `NetSurv`, and I am dropping factor variable `Title`.

```{r}
preds <- c(preds, "AgeCohort", "TicketNCohort", "NetSurv") 
preds <- subset(preds, preds != "Title")
preds_numeric <- c(preds_numeric, "NetSurv") 
```

Let's measure the collinearity of the numeric predictors.  `TicketN` has a high correlation with `SibSp` and `Parch`.  `Parch` has a moderate correlatoin with `SibSp`.  When predictors are correlated, one or both may show low statistical significance.

```{r message=FALSE}
ggpairs(full[train_index, preds_numeric])
```


```{r}
plot_bv_box <- function(dat, num_var, color){
  dat %>% 
    ggplot(aes(y = !!sym(num_var)))
}
```

The following tables break down the factor levels and associated odds ratios with the base level.


# Save Work

Another look at the data.

```{r}
mdl_vars <- c("Survived", preds)
skimr::skim(full[, mdl_vars])
```

For the modeling phase, I'll split the `full` data set into `training` and `testing`, then 80:20 split `training` into `training_80` for training and `training_20` as a holdout set to compare models.

```{r}
training <- full[train_index, ]
testing <- full[-train_index, ]
 
set.seed(1920)
partition <- createDataPartition(training$Survived, p = 0.80, list = FALSE)[, 1]
training_80 <- training[partition, ]
training_20 <- training[-partition, ]
```

Save the objects for the modeling.

```{r}
save(full, train_index, training, testing, training_80, training_20, 
     preds, mdl_vars, file = "./titanic_02.RData")
```

