---
title: "Kaggle - Titanic"
subtitle: "Step 2: Exploratory Analysis"
author: "Michael Foley"
date: "5/7/2020"
output: 
  html_document:
    theme: flatly
    toc: true
    highlight: haddock
    fig_width: 9
    fig_caption: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


This is a survey of the Titanic data.  The univariate analysis characterizes the predictor distributions.  The bivariate analysis characterizes relationships among the predictors and with the response variable.  The influential outliers analysis searches for problematic observations.

# Setup

```{r message=FALSE}
library(tidyverse)
library(caret)  # for nearZeroVar()
library(e1071)  # for skewness()
library(broom)  # for tidy()
library(GGally) # for ggpairs()
library(gridExtra) 
```


# Load Data

The initial data management created the data set `full`, with training rows indexed by `train_index`.

```{r warning=FALSE, message=FALSE}
load("./titanic_01.RData")

glimpse(full)
```

# Univariate Analysis

In this section I will look at data distributions. For factor variables, I am interested in which have near-zero-variance. For quantitative variables, I am looking for significant skew. 

It will be handy to classify the predictors by data type.

```{r}
preds <- full %>% 
  select(-Survived, -PassengerId, -Surname, -Name, -Ticket, -Cabin, -Fare) %>% 
  colnames()
preds_class <- full[, preds] %>% map(class) %>% unlist()
preds_factor <- subset(preds_class, preds_class == "factor") %>% names()
preds_numeric <- subset(preds_class, preds_class %in% c("numeric", "integer")) %>% names()
mdl_vars <- c("Survived", preds)
rm(preds_class)

assertthat::are_equal(length(c(preds_factor, preds_numeric)), length(preds))
```

## Factor Variables

Inspect each factor variable, looking for near-zero-variance (NZV). I might remove them in the modeling pre-process step to prevent zero-variance in cv folds. `caret::nearZeroVar()` defines NZV as a frequency ratio of the most common value to the second most common value frequency >= 19/5 and a unique value percentage <= 10%. (*DataCamp course Machine Learning Toolbox suggests more aggressive thresholds of frequency ratio >= 2 and unique value percentage <= 20%*).

```{r warning=FALSE}
dummies <- dummyVars(~., data = full[, preds_factor], fullRank = FALSE)
dummy_dat <- as.data.frame(predict(dummies, full[, preds_factor]))
(nzv <- dummy_dat %>%
    nearZeroVar(saveMetrics= TRUE)
)
```

The problematic predictors are `Title = "Master"`, `Employee`, and `Deck = "A"`. 

Here is a visualization of the data. Ideally, you want the vars to land in the top left quadrant.  

```{r}
nzv %>%
  data.frame() %>% rownames_to_column(var = "col") %>%
  separate(col, sep = "\\.", into = c("col", "level"), ) %>%
  filter(!is.na(level)) %>%
  ggplot(aes(x = freqRatio, y = percentUnique, 
             color = fct_rev(factor(nzv, labels = c("(okay)", "NZV"))), 
             label = level)) +
  geom_text(check_overlap = TRUE, size = 2, na.rm = TRUE) +
  geom_point(size = 3, alpha = 0.6, na.rm = TRUE) +
  geom_hline(yintercept = 10, linetype = "dashed") +
  geom_vline(xintercept = 95/5, linetype = "dashed") +
  theme(legend.position = "top") +
  labs(title = "Near-Zero Variance of Factor Variables", color = "") +
  facet_wrap(~col)

rm(dummies, dummy_dat, nzv)
```


## Quantitative Variables

Skew can contribute to violation of linearity in linear regressions. I’ll check which variables have significant skew. Skew between 0.5 and 1.0 is generally considered moderate, and skew greater than 1 severe. In the following charts, neglibibly skewed predictors are colored theil, moderately skewed predictors are colored gold and the severely skewed predictors are colored red.

```{r message=FALSE}
col_skew <- map(full[, preds_numeric], skewness) %>% unlist()
col_skew_is_mod <- names(col_skew[abs(col_skew) > .5 & abs(col_skew) <= 1.0])
col_skew_is_high <- names(col_skew[abs(col_skew) > 1.0])
p <- map(
  colnames(full[, preds_numeric]),
  ~ ggplot(full, aes_string(x = .x)) +
    geom_histogram(fill = case_when(.x %in% col_skew_is_mod ~ "goldenrod", 
                                    .x %in% col_skew_is_high ~ "orangered4",
                                    TRUE ~ "cadetblue")) +
    labs(y = "", x = "", title = .x) +
    theme(axis.text.y=element_blank(), plot.title = element_text(size = 10))
)
exec(grid.arrange, ncol = 2, !!!p)

rm(col_skew, col_skew_is_high, col_skew_is_mod)
```


# Bivariate Analysis

In this section I will look at inter-variable relationships. For factor variables, I am interested in which levels have significantly different log survival odds. For quantitative variables, I am looking for linear relationships with log survival odds and low correlations with each other.

```{r cache=TRUE}
dummies_fullrank <- dummyVars(~., data = full[, mdl_vars], fullRank = TRUE)
full_dum <- as.data.frame(predict(dummies_fullrank, full[, mdl_vars]))

cor_out <- full_dum[train_index, ] %>% cor()
cor_out[, "Survived.1"] %>% abs() %>% sort(decreasing = TRUE) %>% head(11)
```
 
`Sex` is by the far the best predictor of survival.  `Title` is second, but recall that it basically combines sex and age. `Pclass` is third.  The next best predictors are numeric: `NetSurv`, `FarePerPass`, `Fare`, and `TktSize`.  No surprises here - you're best bet for survival is to be a rich woman.  Here is a visualization of the relationships.

```{r message=FALSE}
plot_ggpairs <- function(cols) {
full[train_index, ] %>% 
  ggpairs(
    mapping = aes(col = Survived, alpha = 0.2), 
    columns = cols,
    legend = c(1,1),
    lower = list(combo = wrap("facethist", bins = 20))
  ) +
  theme_minimal() +
  theme(legend.position = "bottom") 
}
for(i in 0:6) {
  print(plot_ggpairs(preds[(1:2) + 2*i]))
}
```

The following tables break down the factor levels and associated odds ratios with the base level.

```{r echo=FALSE}
write_tab <- function(dat, group_var){
  fmla <- paste0("Survived ~ ", group_var)

  mdl_obj <- glm(as.formula(fmla), data = dat, family = "binomial") %>%
    tidy() %>%
    mutate(term = str_remove(term, group_var), OR = exp(estimate)) %>% 
    filter(term != "(Intercept)") %>%
    select(term, OR)

  dat %>%
  group_by(!!sym(group_var)) %>%
  summarise(
    Lived = sum(if_else(Survived == "1", 1, 0)),
    Died = sum(if_else(Survived == "0", 1, 0)),
    N = Lived + Died,
    Surv = Lived / N,
    Odds = Surv / (1 - Surv) 
  ) %>%
  ungroup() %>%
  rename(term = !!sym(group_var)) %>%
  mutate(term = as.character(term), Surv = Surv * 100) %>%
  left_join(mdl_obj, by = "term") %>%
  select(term, N, Surv, Odds, OR) %>%
  flextable::flextable() %>% 
  flextable::colformat_int(j = 2) %>% 
  flextable::colformat_num(j = 3, digits = 0, suffix = "%") %>%
  flextable::colformat_num(j = c(4:5)) %>%
  flextable::set_caption(fmla)
}

write_tab(full[train_index, ], group_var = "Sex")

write_tab(full[train_index, ], group_var = "Title")

write_tab(full[train_index, ], group_var = "Pclass")

write_tab(full[train_index, ], group_var = "Embarked")
```


# Influential Outliers

Now I’ll look at influential outliers. When building a predictive model, I only need to address influential outliers for variables that are likely to be important in the final model.  Here are the bivariate relationships between `Survived` and each numeric predictor, controlling for `Sex`.

```{r}
plot_prob <- function(dat, rows, predictor) {
  fmla <- paste0("Survived ~ Sex + ", predictor)
  dat <- dat[rows, c("Survived", "Sex", predictor)]
  glm(fmla, family = "binomial", data = dat) %>%
    augment() %>%
    mutate(Survived_int = as.numeric(Survived) - 1,
           Fitted = exp(.fitted) / (1 + exp(.fitted))) %>%
    ggplot(aes(x = !!sym(predictor), color = Sex)) +
    geom_line(aes(y = exp(.fitted) / (1 + exp(.fitted))), show.legend = FALSE) +
    geom_point(aes(y = Survived_int), alpha = 0.6,
               position = position_jitter(height = .1), show.legend = FALSE) +
#    theme_minimal() +
    scale_color_brewer(palette = "Paired") +
    labs(title = fmla, y = "Probability") +
    facet_wrap(~ Sex)
}
```


```{r fig.height = 3.5}
plot_prob(full, train_index, "Age")
```

The relationship of Survived with `Age` is flat when controlling for `Sex`.  I don't see any high-leverage points.

```{r fig.height = 3.5}
plot_prob(full, train_index, "SibSp")
```

There are a few `SibSp =  8` rows that may be pulling the regression line down.  After capping the values at 5 I ran the plot again, but the slopes were not a lot different. The slopes are different, so I should probably model an interaction effect.

```{r fig.height = 3.5}
plot_prob(full, train_index, "Parch")
```

No outliers here.  Another case where an interaction effect will probably help.

```{r fig.height = 3.5}
plot_prob(full, train_index, "FarePerPass")
```

The 3 training rows with `FarePerPass` ~ $128 all survived.  They look like high-leverage points.  What happens if I cap fair at $100?

```{r fig.height = 3.5}
full %>% mutate(FarePerPass = if_else(FarePerPass > 100, 100, FarePerPass)) %>%
plot_prob(train_index, "FarePerPass")
```

It doesn't seem to make much difference.  Let's try fitting a simple model `Survived ~ FarePerPass` with the taining data, then collapse the large fares and train again.

```{r}
train(
  Survived ~ FarePerPass*Sex,
  data = full[train_index, mdl_vars],
  method = "glm", family = "binomial",
  metric = "Accuracy",
  trControl = trainControl(method = "cv", n = 10)
)
```

Accuracy is 0.796.  Now what happens if I collapse `FarePerPass`?

```{r}
dat <- full[train_index, mdl_vars] %>% mutate(FarePerPass = if_else(FarePerPass > 100, 100, FarePerPass))
train(
  Survived ~ FarePerPass * Sex,
  data = dat,
  method = "glm", family = "binomial",
  metric = "Accuracy",
  trControl = trainControl(method = "cv", n = 10)
)
```

The accuracy is 0.790, so it probably doesn't make sense to collapse `FarePerPass`.

```{r fig.height = 3.5}
plot_prob(full, train_index, "TicketN")
```

I don't see any outliers or interaction effects with `TicketN`.

```{r fig.height = 3.5}
plot_prob(full, train_index, "NetSurv")
```

`NetSurv` has no outliers, but the shapes between males and females are pretting different.  Let's see what interaction effects do. First without interaction effects.

```{r}
train(
  Survived ~ NetSurv + Sex,
  data = full[train_index, mdl_vars],
  method = "glm", family = "binomial",
  metric = "Accuracy",
  trControl = trainControl(method = "cv", n = 10)
)
```

Accuracy is 0.804.  Now with interaction effects.

```{r}
train(
  Survived ~ NetSurv * Sex,
  data = dat,
  method = "glm", family = "binomial",
  metric = "Accuracy",
  trControl = trainControl(method = "cv", n = 10)
)
```

No difference.

# Save Work

I didn't make any changes to the data set, so nothing to save here.

