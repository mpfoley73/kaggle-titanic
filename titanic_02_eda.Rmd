---
title: "Kaggle - Titanic"
subtitle: "Step 2: Exploratory Analysis"
author: "Michael Foley"
date: "5/7/2020"
output: 
  html_document:
    theme: flatly
    toc: true
    highlight: haddock
    fig_width: 9
    fig_caption: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


This is a survey of the Titanic data.  The univariate analysis characterizes the predictor distributions.  The bivariate analysis characterizes relationships among the predictors and with the response variable.  The influential outliers analysis searches for problematic observations.  

Conclusions:

* Factor variables `Employee`, `Deck.A`, and `Title.Master` have near-zero-variance.

* Nearly all of the quantitativ predictors suffer from skew.  It may make sense to transform these variables in modeling, especially for linear regression models.

* `Sex` is by the far the best predictor of survival.  `Title` is second, but recall that it basically combines sex and age. `Pclass` is third. 

* Define an `AgeCohort` predictor for age bins (<16, 16-48, >48).  For linear models, `AgeCohort` should interact with `Age` and `Sex` as `Age*Sex*AgeCohort`. Linear models may also benefit from an interaction between `Sex` and `FamSize`, and between `Sex` and `NetSurv`.


# Setup

```{r message=FALSE}
library(tidyverse)
library(caret)  # for nearZeroVar()
library(e1071)  # for skewness()
library(broom)  # for tidy()
library(GGally) # for ggpairs()
library(gridExtra) 
```


# Load Data

The initial data management created the data set `full`, with training rows indexed by `train_index`.

```{r warning=FALSE, message=FALSE}
load("./titanic_01.RData")

glimpse(full)
```

# Univariate Analysis

In this section I will look at data distributions. For factor variables, I am interested in which have near-zero-variance. For quantitative variables, I am looking for significant skew. 

It will be handy to classify the predictors by data type.

```{r}
preds <- full %>% 
  select(-Survived, -PassengerId, -Surname, -Name, -Ticket, -Cabin, -Fare) %>% 
  colnames()
preds_class <- full[, preds] %>% map(class) %>% unlist()
preds_factor <- subset(preds_class, preds_class == "factor") %>% names()
preds_numeric <- subset(preds_class, preds_class %in% c("numeric", "integer")) %>% names()
mdl_vars <- c("Survived", preds)
rm(preds_class)

assertthat::are_equal(length(c(preds_factor, preds_numeric)), length(preds))
```

## Factor Variables

Inspect each factor variable, looking for near-zero-variance (NZV). I might remove them in the modeling pre-process step to prevent zero-variance in cv folds. `caret::nearZeroVar()` defines NZV as a frequency ratio of the most common value to the second most common value frequency >= 19/5 and a unique value percentage <= 10%. (*DataCamp course Machine Learning Toolbox suggests more aggressive thresholds of frequency ratio >= 2 and unique value percentage <= 20%*).

```{r warning=FALSE}
dummies <- dummyVars(~., data = full[, preds_factor], fullRank = FALSE)
dummy_dat <- as.data.frame(predict(dummies, full[, preds_factor]))
(nzv <- dummy_dat %>%
    nearZeroVar(saveMetrics= TRUE)
)
```

The problematic predictors are `Title = "Master"`, `Employee`, and `Deck = "A"`. 

Here is a visualization of the data. Ideally, you want the vars to land in the top left quadrant.  

```{r}
nzv %>%
  data.frame() %>% rownames_to_column(var = "col") %>%
  separate(col, sep = "\\.", into = c("col", "level"), ) %>%
  filter(!is.na(level)) %>%
  ggplot(aes(x = freqRatio, y = percentUnique, 
             color = fct_rev(factor(nzv, labels = c("(okay)", "NZV"))), 
             label = level)) +
  geom_text(check_overlap = TRUE, size = 2, na.rm = TRUE) +
  geom_point(size = 3, alpha = 0.6, na.rm = TRUE) +
  geom_hline(yintercept = 10, linetype = "dashed") +
  geom_vline(xintercept = 95/5, linetype = "dashed") +
  theme(legend.position = "top") +
  labs(title = "Near-Zero Variance of Factor Variables", color = "") +
  facet_wrap(~col)

rm(dummies, dummy_dat, nzv)
```


## Quantitative Variables

Skew can contribute to violation of linearity in linear regressions. Iâ€™ll check which variables have significant skew. Skew between 0.5 and 1.0 is generally considered moderate, and skew greater than 1 severe. In the following charts, neglibibly skewed predictors are colored theil, moderately skewed predictors are colored gold and the severely skewed predictors are colored red.

```{r message=FALSE}
col_skew <- map(full[, preds_numeric], skewness) %>% unlist()
col_skew_is_mod <- names(col_skew[abs(col_skew) > .5 & abs(col_skew) <= 1.0])
col_skew_is_high <- names(col_skew[abs(col_skew) > 1.0])
p <- map(
  colnames(full[, preds_numeric]),
  ~ ggplot(full, aes_string(x = .x)) +
    geom_histogram(fill = case_when(.x %in% col_skew_is_mod ~ "goldenrod", 
                                    .x %in% col_skew_is_high ~ "orangered4",
                                    TRUE ~ "cadetblue")) +
    labs(y = "", x = "", title = .x) +
    theme(axis.text.y=element_blank(), plot.title = element_text(size = 10))
)
exec(grid.arrange, ncol = 2, !!!p)

rm(col_skew, col_skew_is_high, col_skew_is_mod)
```

Nearly all of the quantitativ predictors suffer from skew.  It may make sense to transform these variables in modeling.

# Bivariate Analysis

In this section I will look at inter-variable relationships. For factor variables, I am interested in which levels have significantly different log survival odds. For quantitative variables, I am looking for linear relationships with log survival odds and low correlations with each other.

```{r cache=TRUE}
dummies_fullrank <- dummyVars(~., data = full[, mdl_vars], fullRank = TRUE)
full_dum <- as.data.frame(predict(dummies_fullrank, full[, mdl_vars]))

cor_out <- full_dum[train_index, ] %>% cor()
cor_out[, "Survived.Yes"] %>% abs() %>% sort(decreasing = TRUE) %>% head(11)
```
 
`Sex` is by the far the best predictor of survival.  `Title` is second, but recall that it basically combines sex and age. `Pclass` is third.  The next best predictors are numeric: `NetSurv`, `FarePerPass`, `Fare`, and `TktSize`.  No surprises here - you're best bet for survival is to be a rich woman.  Here is a visualization of the relationships.

```{r message=FALSE}
plot_ggpairs <- function(cols) {
full[train_index, ] %>% 
  ggpairs(
    mapping = aes(col = Survived, alpha = 0.2), 
    columns = cols,
    legend = c(1,1),
    lower = list(combo = wrap("facethist", bins = 20))
  ) +
  theme_minimal() +
  theme(legend.position = "bottom") 
}
for(i in 0:6) {
  print(plot_ggpairs(preds[(1:2) + 2*i]))
}
```

The following tables break down the factor levels and associated odds ratios with the base level.

```{r echo=FALSE}
write_tab <- function(dat, group_var){
  fmla <- paste0("Survived ~ ", group_var)

  mdl_obj <- glm(as.formula(fmla), data = dat, family = "binomial") %>%
    tidy() %>%
    mutate(term = str_remove(term, group_var), OR = exp(estimate)) %>% 
    filter(term != "(Intercept)") %>%
    select(term, OR)

  dat %>%
  group_by(!!sym(group_var)) %>%
  summarise(
    Lived = sum(if_else(Survived == "Yes", 1, 0)),
    Died = sum(if_else(Survived == "No", 1, 0)),
    N = Lived + Died,
    Surv = Lived / N,
    Odds = Surv / (1 - Surv) 
  ) %>%
  ungroup() %>%
  rename(term = !!sym(group_var)) %>%
  mutate(term = as.character(term), Surv = Surv * 100) %>%
  left_join(mdl_obj, by = "term") %>%
  select(term, N, Surv, Odds, OR) %>%
  flextable::flextable() %>% 
  flextable::colformat_int(j = 2) %>% 
  flextable::colformat_num(j = 3, digits = 0, suffix = "%") %>%
  flextable::colformat_num(j = c(4:5)) %>%
  flextable::set_caption(fmla)
}

write_tab(full[train_index, ], group_var = "Sex")

write_tab(full[train_index, ], group_var = "Title")

write_tab(full[train_index, ], group_var = "Pclass")

write_tab(full[train_index, ], group_var = "Embarked")
```


# Linearity

For linear models like logistic regression, the relationship between the numeric predictors and the log survival odds should be linear.  Look closely at these relationships and see if any transformations might help create linearity.

The conclusions from this section are:

* Define an `AgeCohort` predictor for age bins (<16, 16-48, >48).  For linear models, `AgeCohort` should interact with `Age` and `Sex` as `Age*Sex*AgeCohort`.

* It may help to model an interaction with `Sex` and `FamSize`, and with `Sex` and `NetSurv`.

Define handy functions for this analysis.

```{r}
model_bin <- function(dat, fmla) {
  mdl <- train(
    as.formula(fmla),
    dat,
    method = "glm", family = "binomial",
    metric = "Accuracy",
    trControl = trainControl(method = "cv", n = 10)      
  )
}

plot_bin <- function(dat, x, fmla) {
  dat %>% 
    group_by(Sex, !!sym(x), Survived) %>%
    summarize(n = n(), mean_p = mean(p)) %>%
    ungroup() %>% 
    group_by(Sex, !!sym(x)) %>% 
    mutate(
      N = sum(n), 
      prop = n / N,
      odds = prop / (1 - prop),
      log_odds = log(odds),
      mean_p = mean(mean_p, na.rm = TRUE),
      p_odds = log(mean_p / (1 - mean_p))
    ) %>%
    filter(Survived == "Yes") %>%
    ggplot(aes(x = !!sym(x), fill = N)) +
      geom_col(aes(y = log_odds)) +
      geom_point(aes(y = p_odds)) +
      theme(axis.text.x = element_text(angle = 90)) +
      scale_y_continuous(limits = c(-3.5, 3.5)) +
      labs(title = fmla, x = x) +
      facet_wrap(~Sex)
}
```

## Age

There is a large interaction between sex and age.  Until around age 16, female survival odds increase while males decrease.  From 16 to around 48, survival odds are stable for both sexes.  But after age 48, female survival odds increase while male survival odds decrease. Maybe I should model a 3-way interaction of sex, age, and age cohort (<16, 16-48, >48).

```{r}
fmla = "Survived ~ Sex*AgeCohort*Age"
full <- full %>%
  mutate(
    AgeCohort = case_when(
      Age <= 16 ~ "(0-16)",
      Age <= 48 ~ "(16-48]",
      TRUE ~ "(48-80]"
    ),
    AgeCohort = factor(AgeCohort)
  ) 
dat <- full[train_index, ] %>% mutate(AgeBin = cut(Age, breaks = 20, dig.lab = 2))
mdl <- model_bin(dat, fmla)
dat$p <- mdl$finalModel$fitted.values  
plot_bin(dat, x = "AgeBin", fmla = fmla)
summary(mdl)
```


## SibSp

Males traveling without a spouse or siblings seemed to have a rough go of it.  Otherwise, the odds of survival seemed to fall with increasing numbers of spouse + siblings.  It may help to model an interaction with Sex and family size.

```{r}
fmla = "Survived ~ Sex + SibSp + FamSize*Sex"
dat <- full[train_index, ] 
mdl <- model_bin(dat, fmla)
dat$p <- mdl$finalModel$fitted.values  
plot_bin(dat, x = "SibSp", fmla = fmla)
summary(mdl)
```

## Parch

Males traveling without parents or children seemed to have a rough go of it.  Otherwise, the odds of survival seemed to fall with increasing numbers of parents and children.  The interaction with Sex and family size `FamSize` seems to capture this well enough.

```{r}
fmla = "Survived ~ Sex + Parch + FamSize*Sex"
dat <- full[train_index, ]
mdl <- model_bin(dat, fmla)
dat$p <- mdl$finalModel$fitted.values  
plot_bin(dat, x = "Parch", fmla = fmla)
summary(mdl)
```

## FarePerPass

Survival odds seem to increase with ticket price per passenger with no interaction effects.

```{r}
fmla = "Survived ~ Sex + FarePerPass"
dat <- full[train_index, ] %>% mutate(FareBin = cut(FarePerPass, breaks = 20, dig.lab = 2))
mdl <- model_bin(dat, fmla)
dat$p <- mdl$finalModel$fitted.values  
plot_bin(dat, x = "FareBin", fmla = fmla)
summary(mdl)
```

## NetSurv

There seems to be a small interaction effect between sex and net survivors.

```{r}
fmla = "Survived ~ Sex*NetSurv"
mdl <- model_bin(dat, fmla)
dat$p <- mdl$finalModel$fitted.values  
plot_bin(dat, x = "NetSurv", fmla = fmla)
summary(mdl)
```



# Save Work

Another look at the data.  I've added one variable to the data set (`AgeCohort`).

```{r}
skimr::skim(full)
```

```{r}
save(full, train_index, file = "./titanic_02.RData")
```

